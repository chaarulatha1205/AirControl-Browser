# AirControl-Browser
ğŸš€ Gesture-Based Web Automation System
ğŸ“Œ Overview

This project presents a real-time gesture-controlled web automation system that replaces traditional mouse and keyboard interactions with computer vision-based hand gestures. Using live video input, the system detects, interprets, and maps hand gestures to browser actions, enabling a completely touchless web interaction experience.

The solution integrates robust gesture validation, dual-hand contextual intelligence, and a gesture-based security layer to ensure accurate, secure, and low-latency performance in real-world environments.

âœ¨ Key Features

Dual-Hand Contextual Recognition
Differentiates between left and right hands, allowing identical gestures to perform different actions and increasing command flexibility without adding complexity.

Temporal Gesture Validation
Implements time-based confirmation logic to eliminate accidental triggers and improve system stability.

Gesture-Driven Security Layer
Includes an admin-controlled reset mechanism and controlled gesture access to prevent unauthorized usage.

Real-Time Processing Pipeline
Optimized frame processing ensures smooth and responsive browser automation with minimal latency.

Touchless Web Automation
Enables scrolling, clicking, navigation, and other browser interactions using natural hand movements.

ğŸ› ï¸ Tech Stack

Python â€“ Core system logic and orchestration

OpenCV â€“ Real-time video capture and frame processing

MediaPipe Hands â€“ High-precision hand landmark detection

NumPy â€“ Mathematical computations and gesture feature extraction

PyAutoGUI / Selenium â€“ Browser and system automation control

ğŸ§  System Architecture

Capture live video feed using OpenCV.

Detect and track 21 hand landmarks using MediaPipe Hands.

Process landmark coordinates to classify gestures.

Apply temporal validation logic for reliability.

Map validated gestures to browser automation commands.

ğŸŒ Real-World Applications

Accessibility-focused computing

Sterile environment interaction (medical labs, clean rooms)

Hands-free productivity systems

Smart interface prototypes

Humanâ€“Computer Interaction (HCI) research

ğŸ¯ Learning Outcomes

Implemented a real-time computer vision pipeline

Designed gesture recognition logic using landmark-based analysis

Applied HCI principles to build an intuitive touchless interface

Optimized latency and reduced false-positive triggers
